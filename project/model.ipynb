{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from keras.layers import Input, Embedding, SpatialDropout1D, CuDNNGRU, CuDNNLSTM, Bidirectional, \\\n",
    "    Dense, Dropout, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "from attention import Attention\n",
    "from f1_early_stopping import F1_EarlyStopping, find_threshold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from cyclic_lr import CyclicLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(KerasTokenizer):\n",
    "    _NON_ASCII_PATTERN = re.compile(r'[^\\x00-\\x7f]')\n",
    "    _SPECIAL_ASCII_CHARACTERS = re.compile(r'[\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x1f]')\n",
    "    \n",
    "    def __init__(self, tokenizer=word_tokenize, *args, **kwargs):\n",
    "        super(Tokenizer, self).__init__(*args, **kwargs)\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def _preprocess(self, text):\n",
    "        text = Tokenizer._NON_ASCII_PATTERN.sub(' ', text)\n",
    "        text = Tokenizer._SPECIAL_ASCII_CHARACTERS.sub('', text)\n",
    "        return ' '.join(self.tokenizer(text))\n",
    "    \n",
    "    def fit_on_texts(self, texts):\n",
    "        return super(Tokenizer, self).fit_on_texts([\n",
    "            self._preprocess(text)\n",
    "            for text in texts\n",
    "        ])\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        return super(Tokenizer, self).texts_to_sequences([\n",
    "            self._preprocess(text)\n",
    "            for text in texts\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 95000\n",
    "tokenizer = Tokenizer(num_words=95000)\n",
    "tokenizer.fit_on_texts(train['question_text'])\n",
    "train_X = tokenizer.texts_to_sequences(train['question_text'])\n",
    "test_X = tokenizer.texts_to_sequences(test['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_X).apply(len).quantile(0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 70\n",
    "train_X = pad_sequences(train_X, MAXLEN)\n",
    "test_X = pad_sequences(test_X, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove(fname, encoding='utf-8', errors='ignore'):\n",
    "    word2index = {}\n",
    "    vectors = []\n",
    "    with open(fname, 'r', encoding=encoding, errors=errors) as src:\n",
    "        for i, line in enumerate(src):\n",
    "            if not line:\n",
    "                break\n",
    "            parts = line.split(' ')\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:]).astype(np.float32)\n",
    "            word2index[word] = i\n",
    "            vectors.append(vector)\n",
    "    return word2index, np.array(vectors)\n",
    "\n",
    "\n",
    "def lowercase_word_index(word2index):\n",
    "    lowercased = {\n",
    "        word.lower(): index\n",
    "        for word, index in word2index.items()\n",
    "    }\n",
    "    return dict(lowercased, **word2index)\n",
    "\n",
    "\n",
    "def vocab_oov_split(word2index, tokenizer):\n",
    "    known_words = set(tokenizer.word_index.keys())\n",
    "    vocabulary_words = set(word2index.keys())\n",
    "    return sorted(known_words & vocabulary_words), sorted(known_words - vocabulary_words)\n",
    "\n",
    "\n",
    "def vocabulary_embedding(word2index, embeddings, tokenizer, vocabulary):\n",
    "    embeddings_final = np.zeros([len(tokenizer.word_index) + 1, embeddings.shape[1]])\n",
    "    for word in vocabulary:\n",
    "        final_idx = tokenizer.word_index[word]\n",
    "        current_idx = word2index[word]\n",
    "        embeddings_final[final_idx] = embeddings[current_idx, :]\n",
    "    return embeddings_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragram_word2index, paragram_embeddings = read_glove('../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt')\n",
    "paragram_word2index_lowercased = lowercase_word_index(paragram_word2index)\n",
    "paragram_vocabulary, paragram_oov = vocab_oov_split(paragram_word2index_lowercased, tokenizer)\n",
    "paragram_embeddings_cutten = vocabulary_embedding(paragram_word2index_lowercased, paragram_embeddings, tokenizer, paragram_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_word2index, glove_embeddings = read_glove('../input/embeddings/glove.840B.300d/glove.840B.300d.txt')\n",
    "glove_word2index_lowercased = lowercase_word_index(glove_word2index)\n",
    "glove_vocabulary, glove_oov = vocab_oov_split(glove_word2index_lowercased, tokenizer)\n",
    "glove_embeddings_cutten = vocabulary_embedding(glove_word2index_lowercased, glove_embeddings, tokenizer, glove_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del paragram_embeddings, glove_embeddings\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = (paragram_embeddings_cutten + glove_embeddings_cutten) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(embeddings):\n",
    "    inp = Input(shape=(MAXLEN,))\n",
    "    x = Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], trainable=False)(inp)\n",
    "    x = SpatialDropout1D(0.05)(x)\n",
    "    \n",
    "    x = Bidirectional(CuDNNLSTM(40, return_sequences=True))(x)\n",
    "    atten_1 = Attention(MAXLEN)(x) # skip connect\n",
    "    \n",
    "    y = Bidirectional(CuDNNGRU(40, return_sequences=True))(x)\n",
    "    atten_2 = Attention(MAXLEN)(y)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(y)\n",
    "    max_pool = GlobalMaxPooling1D()(y)\n",
    "    \n",
    "    conc = concatenate([atten_1, atten_2, avg_pool, max_pool])\n",
    "    \n",
    "    conc = Dense(16, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.2)(conc)\n",
    "    outp = Dense(1, activation=\"sigmoid\")(conc)    \n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 979591 samples, validate on 326531 samples\n",
      "Epoch 1/8\n",
      "979591/979591 [==============================] - 176s 180us/step - loss: 0.1178 - acc: 0.9549 - val_loss: 0.1048 - val_acc: 0.9586\n",
      "Epoch 0 train finished. Checking classification quality.\n",
      "Val F1: 0.6611072823340225\n",
      "Updated model\n",
      "Epoch 2/8\n",
      "979591/979591 [==============================] - 172s 176us/step - loss: 0.1021 - acc: 0.9595 - val_loss: 0.1020 - val_acc: 0.9583\n",
      "Epoch 1 train finished. Checking classification quality.\n",
      "Val F1: 0.6746587370343488\n",
      "Updated model\n",
      "Epoch 3/8\n",
      "979591/979591 [==============================] - 175s 179us/step - loss: 0.0960 - acc: 0.9614 - val_loss: 0.1002 - val_acc: 0.9604\n",
      "Epoch 2 train finished. Checking classification quality.\n",
      "Val F1: 0.6799371882505081\n",
      "Updated model\n",
      "Epoch 4/8\n",
      "979591/979591 [==============================] - 171s 175us/step - loss: 0.0913 - acc: 0.9630 - val_loss: 0.1014 - val_acc: 0.9604\n",
      "Epoch 3 train finished. Checking classification quality.\n",
      "Val F1: 0.6788297627274821\n",
      "Finished training. Returned to best state.\n",
      "********************************************************************************\n",
      "Train on 979591 samples, validate on 326531 samples\n",
      "Epoch 1/8\n",
      "979591/979591 [==============================] - 179s 183us/step - loss: 0.1183 - acc: 0.9548 - val_loss: 0.1034 - val_acc: 0.9586\n",
      "Epoch 0 train finished. Checking classification quality.\n",
      "Val F1: 0.6640594265614514\n",
      "Updated model\n",
      "Epoch 2/8\n",
      "979591/979591 [==============================] - 178s 182us/step - loss: 0.1028 - acc: 0.9595 - val_loss: 0.0998 - val_acc: 0.9598\n",
      "Epoch 1 train finished. Checking classification quality.\n",
      "Val F1: 0.6769407178075909\n",
      "Updated model\n",
      "Epoch 3/8\n",
      "979591/979591 [==============================] - 174s 178us/step - loss: 0.0968 - acc: 0.9612 - val_loss: 0.0997 - val_acc: 0.9606\n",
      "Epoch 2 train finished. Checking classification quality.\n",
      "Val F1: 0.6809817367412435\n",
      "Updated model\n",
      "Epoch 4/8\n",
      "979591/979591 [==============================] - 173s 177us/step - loss: 0.0920 - acc: 0.9628 - val_loss: 0.0987 - val_acc: 0.9603\n",
      "Epoch 3 train finished. Checking classification quality.\n",
      "Val F1: 0.6810568364987035\n",
      "Updated model\n",
      "Epoch 5/8\n",
      "979591/979591 [==============================] - 174s 178us/step - loss: 0.0875 - acc: 0.9642 - val_loss: 0.1005 - val_acc: 0.9600\n",
      "Epoch 4 train finished. Checking classification quality.\n",
      "Val F1: 0.6814903293977121\n",
      "Updated model\n",
      "Epoch 6/8\n",
      "979591/979591 [==============================] - 174s 178us/step - loss: 0.0835 - acc: 0.9656 - val_loss: 0.1010 - val_acc: 0.9599\n",
      "Epoch 5 train finished. Checking classification quality.\n",
      "Val F1: 0.6798812072656952\n",
      "Finished training. Returned to best state.\n",
      "********************************************************************************\n",
      "Train on 979592 samples, validate on 326530 samples\n",
      "Epoch 1/8\n",
      "979592/979592 [==============================] - 175s 179us/step - loss: 0.1180 - acc: 0.9548 - val_loss: 0.1028 - val_acc: 0.9592\n",
      "Epoch 0 train finished. Checking classification quality.\n",
      "Val F1: 0.6657926815244141\n",
      "Updated model\n",
      "Epoch 2/8\n",
      "979592/979592 [==============================] - 179s 183us/step - loss: 0.1022 - acc: 0.9595 - val_loss: 0.0991 - val_acc: 0.9602\n",
      "Epoch 1 train finished. Checking classification quality.\n",
      "Val F1: 0.6781912431731927\n",
      "Updated model\n",
      "Epoch 3/8\n",
      "979592/979592 [==============================] - 176s 180us/step - loss: 0.0962 - acc: 0.9616 - val_loss: 0.0979 - val_acc: 0.9608\n",
      "Epoch 2 train finished. Checking classification quality.\n",
      "Val F1: 0.682936908807053\n",
      "Updated model\n",
      "Epoch 4/8\n",
      "979592/979592 [==============================] - 176s 179us/step - loss: 0.0912 - acc: 0.9630 - val_loss: 0.0982 - val_acc: 0.9608\n",
      "Epoch 3 train finished. Checking classification quality.\n",
      "Val F1: 0.68235732761634\n",
      "Finished training. Returned to best state.\n",
      "********************************************************************************\n",
      "Train on 979592 samples, validate on 326530 samples\n",
      "Epoch 1/8\n",
      "979592/979592 [==============================] - 176s 179us/step - loss: 0.1196 - acc: 0.9548 - val_loss: 0.1068 - val_acc: 0.9564\n",
      "Epoch 0 train finished. Checking classification quality.\n",
      "Val F1: 0.6646858301087157\n",
      "Updated model\n",
      "Epoch 2/8\n",
      "979592/979592 [==============================] - 179s 182us/step - loss: 0.1032 - acc: 0.9591 - val_loss: 0.0993 - val_acc: 0.9600\n",
      "Epoch 1 train finished. Checking classification quality.\n",
      "Val F1: 0.6774378103759985\n",
      "Updated model\n",
      "Epoch 3/8\n",
      "979592/979592 [==============================] - 176s 180us/step - loss: 0.0970 - acc: 0.9612 - val_loss: 0.0978 - val_acc: 0.9609\n",
      "Epoch 2 train finished. Checking classification quality.\n",
      "Val F1: 0.6828139820019895\n",
      "Updated model\n",
      "Epoch 4/8\n",
      "979592/979592 [==============================] - 176s 180us/step - loss: 0.0917 - acc: 0.9627 - val_loss: 0.0998 - val_acc: 0.9592\n",
      "Epoch 3 train finished. Checking classification quality.\n",
      "Val F1: 0.6847811170577741\n",
      "Updated model\n",
      "Epoch 5/8\n",
      "979592/979592 [==============================] - 176s 179us/step - loss: 0.0873 - acc: 0.9644 - val_loss: 0.0989 - val_acc: 0.9606\n",
      "Epoch 4 train finished. Checking classification quality.\n",
      "Val F1: 0.6827839509042727\n",
      "Finished training. Returned to best state.\n",
      "********************************************************************************\n",
      "Mean score: 0.6822863858782618\n",
      "Score std: 0.0017888054081832672\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "tf.set_random_seed(RANDOM_STATE)\n",
    "\n",
    "models = []\n",
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=RANDOM_STATE)\n",
    "scores = []\n",
    "for idx_train, idx_val in kfold.split(train_X, train_y):\n",
    "    model = get_model(embeddings)\n",
    "    f1_callback = F1_EarlyStopping(train_X[idx_train], train_y[idx_train],\n",
    "                                   train_X[idx_val], train_y[idx_val],\n",
    "                                   batch_size=1024)\n",
    "    model.fit(train_X[idx_train], train_y[idx_train],\n",
    "              validation_data=(train_X[idx_val], train_y[idx_val]),\n",
    "              epochs=8,\n",
    "              verbose=True,\n",
    "              batch_size=256,\n",
    "              callbacks=[\n",
    "                  CyclicLR(base_lr=0.001, max_lr=0.002,\n",
    "                           step_size=300., mode='exp_range',\n",
    "                           gamma=0.99994),\n",
    "                  f1_callback,\n",
    "              ])\n",
    "    scores.append(f1_callback.best_score)\n",
    "    models.append(model)\n",
    "    print('*' * 80)\n",
    "    \n",
    "scores = np.array(scores)\n",
    "print('Mean score: {0}'.format(np.mean(scores)))\n",
    "print('Score std: {0}'.format(np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    model.save('model-{0}.h5'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"''how\",\n",
       " \"''kate\",\n",
       " \"''national\",\n",
       " \"''religion\",\n",
       " \"''that\",\n",
       " \"''why\",\n",
       " \"'0\",\n",
       " \"'00000000000000000021e800\",\n",
       " \"'00s\",\n",
       " \"'1\",\n",
       " \"'1'54'am\",\n",
       " \"'100\",\n",
       " \"'102\",\n",
       " \"'10x\",\n",
       " \"'110\",\n",
       " \"'1967\",\n",
       " \"'200\",\n",
       " \"'2009\",\n",
       " \"'2099\",\n",
       " \"'2nd\",\n",
       " \"'2r\",\n",
       " \"'3\",\n",
       " \"'301\",\n",
       " \"'4\",\n",
       " \"'4'\",\n",
       " \"'4'it\",\n",
       " \"'403\",\n",
       " \"'4k\",\n",
       " \"'5\",\n",
       " \"'500\",\n",
       " \"'539\",\n",
       " \"'6\",\n",
       " \"'666\",\n",
       " \"'7\",\n",
       " \"'777888999\",\n",
       " \"'8\",\n",
       " \"'a\",\n",
       " \"'a'units\",\n",
       " \"'a2a\",\n",
       " \"'aa\",\n",
       " \"'aaji\",\n",
       " \"'aajkal\",\n",
       " \"'aap\",\n",
       " \"'aazadi\",\n",
       " \"'ab\",\n",
       " \"'abdullah\",\n",
       " \"'ability\",\n",
       " \"'abode\",\n",
       " \"'abortion\",\n",
       " \"'about\",\n",
       " \"'above\",\n",
       " \"'abracadabra\",\n",
       " \"'abuse\",\n",
       " \"'acceleration\",\n",
       " \"'accept\",\n",
       " \"'acceptable\",\n",
       " \"'access\",\n",
       " \"'accha\",\n",
       " \"'accident\",\n",
       " \"'accidental\",\n",
       " \"'accidentally\",\n",
       " \"'acclaimed\",\n",
       " \"'accomplishments\",\n",
       " \"'accurate\",\n",
       " \"'accuser\",\n",
       " \"'achievement\",\n",
       " \"'act\",\n",
       " \"'acting\",\n",
       " \"'actioning\",\n",
       " \"'active\",\n",
       " \"'actively\",\n",
       " \"'actor\",\n",
       " \"'actors\",\n",
       " \"'actually\",\n",
       " \"'adam\",\n",
       " \"'adapted\",\n",
       " \"'adaption\",\n",
       " \"'adat\",\n",
       " \"'add\",\n",
       " \"'addams\",\n",
       " \"'addicting\",\n",
       " \"'addictive\",\n",
       " \"'additional\",\n",
       " \"'adds\",\n",
       " \"'adiye\",\n",
       " \"'adjust\",\n",
       " \"'administrators\",\n",
       " \"'adobe\",\n",
       " \"'adoctrinamiento\",\n",
       " \"'adolf\",\n",
       " \"'adolph\",\n",
       " \"'adoptive\",\n",
       " \"'adult\",\n",
       " \"'advanced\",\n",
       " \"'advisor\",\n",
       " \"'advocacy\",\n",
       " \"'afflict\",\n",
       " \"'affray\",\n",
       " \"'afra\",\n",
       " \"'afreen\",\n",
       " \"'after\",\n",
       " \"'agar\",\n",
       " \"'age\",\n",
       " \"'aged\",\n",
       " \"'ageing\",\n",
       " \"'agender\",\n",
       " \"'ago\",\n",
       " \"'agree\",\n",
       " \"'ah\",\n",
       " \"'aha\",\n",
       " \"'aham\",\n",
       " \"'ahmadis\",\n",
       " \"'aib\",\n",
       " \"'air\",\n",
       " \"'airline\",\n",
       " \"'airplane\",\n",
       " \"'airtel\",\n",
       " \"'aisha\",\n",
       " \"'aishwarya\",\n",
       " \"'akale\",\n",
       " \"'akhanda\",\n",
       " \"'akinator\",\n",
       " \"'aksar\",\n",
       " \"'al\",\n",
       " \"'alastor\",\n",
       " \"'albino\",\n",
       " \"'alex\",\n",
       " \"'algorithm\",\n",
       " \"'alhamdulillah\",\n",
       " \"'ali\",\n",
       " \"'alias\",\n",
       " \"'alice\",\n",
       " \"'alien\",\n",
       " \"'aliens\",\n",
       " \"'alive\",\n",
       " \"'all\",\n",
       " \"'allahu\",\n",
       " \"'alleged\",\n",
       " \"'allegedly\",\n",
       " \"'allegretto\",\n",
       " \"'allison\",\n",
       " \"'aloko\",\n",
       " \"'alpaca\",\n",
       " \"'alplexle\",\n",
       " \"'also\",\n",
       " \"'alt\",\n",
       " \"'altaba\",\n",
       " \"'alternative\",\n",
       " \"'alternote\",\n",
       " \"'always\",\n",
       " \"'am\",\n",
       " \"'amar\",\n",
       " \"'amateur\",\n",
       " \"'amazigh\",\n",
       " \"'amazon\",\n",
       " \"'ambani\",\n",
       " \"'ambulance\",\n",
       " \"'america\",\n",
       " \"'american\",\n",
       " \"'americans\",\n",
       " \"'americasians\",\n",
       " \"'amnesty\",\n",
       " \"'among\",\n",
       " \"'amy\",\n",
       " \"'an\",\n",
       " \"'analog\",\n",
       " \"'ananupurvi\",\n",
       " \"'anarchist\",\n",
       " \"'anarchy\",\n",
       " \"'ancient\",\n",
       " \"'and\",\n",
       " \"'andromaque\",\n",
       " \"'anecdotal\",\n",
       " \"'anekantwad\",\n",
       " \"'angel\",\n",
       " \"'angelic\",\n",
       " \"'anger\",\n",
       " \"'angry\",\n",
       " \"'animal\",\n",
       " \"'animalistic\",\n",
       " \"'animals\",\n",
       " \"'ankeeta\",\n",
       " \"'annapai\",\n",
       " \"'annoyed\",\n",
       " \"'annoying\",\n",
       " \"'annual\",\n",
       " \"'annuity\",\n",
       " \"'annum\",\n",
       " \"'anonymous\",\n",
       " \"'anonymously\",\n",
       " \"'anoop\",\n",
       " \"'ans\",\n",
       " \"'answer\",\n",
       " \"'ant\",\n",
       " \"'antaryami\",\n",
       " \"'anthropophobia\",\n",
       " \"'anti\",\n",
       " \"'anticipation\",\n",
       " \"'antifa\",\n",
       " \"'antigens\",\n",
       " \"'antiquities\",\n",
       " \"'antisemitic\",\n",
       " \"'anxiety\",\n",
       " \"'any\",\n",
       " \"'anything\",\n",
       " \"'anyway\",\n",
       " \"'anyways\",\n",
       " \"'apartheid\",\n",
       " \"'apoapsis\",\n",
       " \"'apologized\",\n",
       " \"'apology\",\n",
       " \"'app\",\n",
       " \"'apparatus\",\n",
       " \"'apparent\",\n",
       " \"'apparently\",\n",
       " \"'appearing\",\n",
       " \"'appeasement\",\n",
       " \"'apple\",\n",
       " \"'appreciation\",\n",
       " \"'approach\",\n",
       " \"'apyayatha\",\n",
       " \"'arab\",\n",
       " \"'arabian\",\n",
       " \"'arbitrary\",\n",
       " \"'archer\",\n",
       " \"'architecture\",\n",
       " \"'are\",\n",
       " \"'arifi\",\n",
       " \"'arijit\",\n",
       " \"'arjuna\",\n",
       " \"'arm\",\n",
       " \"'armed\",\n",
       " \"'armour\",\n",
       " \"'arpita\",\n",
       " \"'arrests\",\n",
       " \"'arrival\",\n",
       " \"'arrow\",\n",
       " \"'art\",\n",
       " \"'article\",\n",
       " \"'artificial\",\n",
       " \"'aruvi\",\n",
       " \"'as\",\n",
       " \"'ashkenazi\",\n",
       " \"'asians\",\n",
       " \"'ask\",\n",
       " \"'askreddit\",\n",
       " \"'asleeping\",\n",
       " \"'ass\",\n",
       " \"'assault\",\n",
       " \"'assigned\",\n",
       " \"'association\",\n",
       " \"'asuras\",\n",
       " \"'at\",\n",
       " \"'ataturk\",\n",
       " \"'ate\",\n",
       " \"'atheism\",\n",
       " \"'atheist\",\n",
       " \"'ati\",\n",
       " \"'atom\",\n",
       " \"'atomic\",\n",
       " \"'atrocity\",\n",
       " \"'attack\",\n",
       " \"'attacks\",\n",
       " \"'attractive\",\n",
       " \"'audacious\",\n",
       " \"'audacity\",\n",
       " \"'aukad\",\n",
       " \"'aunty\",\n",
       " \"'aurangzeb\",\n",
       " \"'authentic'\",\n",
       " \"'author'\",\n",
       " \"'authored\",\n",
       " \"'authorities\",\n",
       " \"'authority\",\n",
       " \"'avada\",\n",
       " \"'avengers\",\n",
       " \"'average\",\n",
       " \"'avoid\",\n",
       " \"'award\",\n",
       " \"'awkward\",\n",
       " \"'awrt\",\n",
       " \"'axiom\",\n",
       " \"'axon\",\n",
       " \"'ayesha\",\n",
       " \"'azerbaijani\",\n",
       " \"'b\",\n",
       " \"'b2\",\n",
       " \"'b3\",\n",
       " \"'baadshaho\",\n",
       " \"'baahubali\",\n",
       " \"'baalig\",\n",
       " \"'baba\",\n",
       " \"'babe\",\n",
       " \"'babies\",\n",
       " \"'babu\",\n",
       " \"'baby\",\n",
       " \"'baccha\",\n",
       " \"'bacha\",\n",
       " \"'bachche\",\n",
       " \"'bachelor\",\n",
       " \"'bachelors\",\n",
       " \"'back\",\n",
       " \"'background\",\n",
       " \"'backlog\",\n",
       " \"'bacon\",\n",
       " \"'bad\",\n",
       " \"'badly\",\n",
       " \"'bae\",\n",
       " \"'bagvadgita\",\n",
       " \"'baidu\",\n",
       " \"'bakkushan\",\n",
       " \"'baklava\",\n",
       " \"'bal\",\n",
       " \"'balaclava\",\n",
       " \"'balances\",\n",
       " \"'ballad\",\n",
       " \"'bama\",\n",
       " \"'band\",\n",
       " \"'bandhan\",\n",
       " \"'bang\",\n",
       " \"'bangladesh\",\n",
       " \"'bangladeshis\",\n",
       " \"'banglore\",\n",
       " \"'baniya\",\n",
       " \"'baniyas\",\n",
       " \"'bank\",\n",
       " \"'bankable\",\n",
       " \"'banking\",\n",
       " \"'bankroll\",\n",
       " \"'bar\",\n",
       " \"'bare\",\n",
       " \"'barka\",\n",
       " \"'bart\",\n",
       " \"'barter\",\n",
       " \"'basal\",\n",
       " \"'base\",\n",
       " \"'based\",\n",
       " \"'baselining\",\n",
       " \"'basic\",\n",
       " \"'basics\",\n",
       " \"'basing\",\n",
       " \"'basket\",\n",
       " \"'batman\",\n",
       " \"'battle\",\n",
       " \"'bbc\",\n",
       " \"'be\",\n",
       " \"'beautiful\",\n",
       " \"'became\",\n",
       " \"'because\",\n",
       " \"'becky\",\n",
       " \"'become\",\n",
       " \"'becoming\",\n",
       " \"'before\",\n",
       " \"'behavioral\",\n",
       " \"'behavioural\",\n",
       " \"'behind\",\n",
       " \"'being\",\n",
       " \"'belief\",\n",
       " \"'believe\",\n",
       " \"'believers\",\n",
       " \"'believing\",\n",
       " \"'belle\",\n",
       " \"'belly\",\n",
       " \"'ben\",\n",
       " \"'bender\",\n",
       " \"'bending\",\n",
       " \"'benefit\",\n",
       " \"'bengaluru\",\n",
       " \"'berkeley\",\n",
       " \"'berserk\",\n",
       " \"'best\",\n",
       " \"'bestfriends\",\n",
       " \"'bet\",\n",
       " \"'beta\",\n",
       " \"'beti\",\n",
       " \"'better\",\n",
       " \"'between\",\n",
       " \"'beurette\",\n",
       " \"'bey\",\n",
       " \"'beyhadh\",\n",
       " \"'beyond\",\n",
       " \"'bhagwan\",\n",
       " \"'bhaisaheb\",\n",
       " \"'bhakt\",\n",
       " \"'bhakts\",\n",
       " \"'bhandary\",\n",
       " \"'bhangi\",\n",
       " \"'bharat\",\n",
       " \"'bhavesh\",\n",
       " \"'bheege\",\n",
       " \"'bhim\",\n",
       " \"'bhutta\",\n",
       " \"'bic\",\n",
       " \"'bien\",\n",
       " \"'big\",\n",
       " \"'bigger\",\n",
       " \"'biggest\",\n",
       " \"'bigly\",\n",
       " \"'bill\",\n",
       " \"'billionaire\",\n",
       " \"'billy\",\n",
       " \"'bimbo\",\n",
       " \"'bind\",\n",
       " \"'biogical\",\n",
       " \"'bioinformatics\",\n",
       " \"'birds\",\n",
       " \"'birth\",\n",
       " \"'bit\",\n",
       " \"'bitch\",\n",
       " \"'bitcheese\",\n",
       " \"'bitches\",\n",
       " \"'bitcoin\",\n",
       " \"'biting\",\n",
       " \"'bjp\",\n",
       " \"'black\",\n",
       " \"'blacker\",\n",
       " \"'blacking\",\n",
       " \"'blacklist\",\n",
       " \"'blacklisted\",\n",
       " \"'blackmail\",\n",
       " \"'blacks\",\n",
       " \"'blah\",\n",
       " \"'blaming\",\n",
       " \"'blanket\",\n",
       " \"'blasphemers\",\n",
       " \"'bleach\",\n",
       " \"'bless\",\n",
       " \"'blessed\",\n",
       " \"'blinded\",\n",
       " \"'blindspot\",\n",
       " \"'blockchain\",\n",
       " \"'blogger\",\n",
       " \"'blood\",\n",
       " \"'blown\",\n",
       " \"'blue\",\n",
       " \"'blueprints\",\n",
       " \"'blues\",\n",
       " \"'bluetooth\",\n",
       " \"'blunder\",\n",
       " \"'blur\",\n",
       " \"'bob\",\n",
       " \"'bodhgaya\",\n",
       " \"'body\",\n",
       " \"'bohemian\",\n",
       " \"'boli\",\n",
       " \"'bolsomito\",\n",
       " \"'bomb\",\n",
       " \"'bonanza\",\n",
       " \"'bond\",\n",
       " \"'bone\",\n",
       " \"'bonespur\",\n",
       " \"'boneyard\",\n",
       " \"'boo\",\n",
       " \"'boobs\",\n",
       " \"'book\",\n",
       " \"'boom\",\n",
       " \"'boondocks\",\n",
       " \"'boot\",\n",
       " \"'bootstrap\",\n",
       " \"'booty\",\n",
       " \"'boring\",\n",
       " \"'born\",\n",
       " \"'borrow\",\n",
       " \"'bossy\",\n",
       " \"'bot\",\n",
       " \"'both\",\n",
       " \"'bots\",\n",
       " \"'bottle\",\n",
       " \"'bottom\",\n",
       " \"'bought\",\n",
       " \"'bounce\",\n",
       " \"'bovanoskification\",\n",
       " \"'box\",\n",
       " \"'boxes\",\n",
       " \"'boys\",\n",
       " \"'brahmin\",\n",
       " \"'brain\",\n",
       " \"'brainstorm\",\n",
       " \"'brainwash\",\n",
       " \"'branching\",\n",
       " \"'brand\",\n",
       " \"'brandless\",\n",
       " \"'brasil\",\n",
       " \"'brass\",\n",
       " \"'brave\",\n",
       " \"'bravo\",\n",
       " \"'brazil\",\n",
       " \"'breach\",\n",
       " \"'bread\",\n",
       " \"'break\",\n",
       " \"'breakeven\",\n",
       " \"'breaks\",\n",
       " \"'breathe\",\n",
       " \"'breed\",\n",
       " \"'brexit\",\n",
       " \"'bridge\",\n",
       " \"'bridges\",\n",
       " \"'bright\",\n",
       " \"'brightest\",\n",
       " \"'bring\",\n",
       " \"'briony\",\n",
       " \"'brit\",\n",
       " \"'britain\",\n",
       " \"'british\",\n",
       " \"'britons\",\n",
       " \"'bro\",\n",
       " \"'broadway\",\n",
       " \"'broken\",\n",
       " \"'bronzemann\",\n",
       " \"'brother\",\n",
       " \"'brown\",\n",
       " \"'brownie\",\n",
       " \"'browse\",\n",
       " \"'bruce\",\n",
       " \"'bruh\",\n",
       " \"'bts\",\n",
       " \"'buggy\",\n",
       " \"'bullet\",\n",
       " \"'bullied\",\n",
       " \"'bullies\",\n",
       " \"'bullseye\",\n",
       " \"'bungalow\",\n",
       " \"'burden\",\n",
       " \"'bureaucracy\",\n",
       " \"'burn\",\n",
       " \"'burning\",\n",
       " \"'burnt\",\n",
       " \"'burp\",\n",
       " \"'burq\",\n",
       " \"'bushism\",\n",
       " \"'business\",\n",
       " \"'bust\",\n",
       " \"'busy\",\n",
       " \"'but\",\n",
       " \"'butt\",\n",
       " \"'butterface\",\n",
       " \"'butterfly\",\n",
       " \"'button\",\n",
       " \"'buy\",\n",
       " \"'buying\",\n",
       " \"'by\",\n",
       " \"'bystander\",\n",
       " \"'byte\",\n",
       " \"'c\",\n",
       " \"'ca\",\n",
       " \"'cable\",\n",
       " \"'cabover\",\n",
       " \"'cagnolino\",\n",
       " \"'calculate\",\n",
       " \"'calendar\",\n",
       " \"'calf\",\n",
       " \"'calibrated\",\n",
       " \"'california\",\n",
       " \"'call\",\n",
       " \"'called\",\n",
       " \"'calling\",\n",
       " \"'calls\",\n",
       " \"'cally\",\n",
       " \"'camila\",\n",
       " \"'camp\",\n",
       " \"'campaign\",\n",
       " \"'can\",\n",
       " \"'canada\",\n",
       " \"'canadian\",\n",
       " \"'candidate\",\n",
       " \"'capacitance\",\n",
       " \"'capitalism\",\n",
       " \"'capitalist\",\n",
       " \"'carbon\",\n",
       " \"'care\",\n",
       " \"'careless\",\n",
       " \"'carly\",\n",
       " \"'carried\",\n",
       " \"'carrier\",\n",
       " \"'cart\",\n",
       " \"'cases\",\n",
       " \"'cash\",\n",
       " \"'cashed\",\n",
       " \"'cashless\",\n",
       " \"'cast\",\n",
       " \"'caste\",\n",
       " \"'casting\",\n",
       " \"'castle\",\n",
       " \"'casual\",\n",
       " \"'catching\",\n",
       " \"'category\",\n",
       " \"'catfishing\",\n",
       " \"'cathedral\",\n",
       " \"'catherine\",\n",
       " \"'cats\",\n",
       " \"'cattle\",\n",
       " \"'catwalking\",\n",
       " \"'causal\",\n",
       " \"'causative\",\n",
       " \"'ce\",\n",
       " \"'cecilia\",\n",
       " \"'celebrity\",\n",
       " \"'celestial\",\n",
       " \"'cell\",\n",
       " \"'center\",\n",
       " \"'central\",\n",
       " \"'centrists\",\n",
       " \"'certainty\",\n",
       " \"'certified\",\n",
       " \"'chah\",\n",
       " \"'chai\",\n",
       " \"'chain\",\n",
       " \"'chaiwala\",\n",
       " \"'chalta\",\n",
       " \"'chamcha\",\n",
       " \"'chamchagiri\",\n",
       " \"'chamchas\",\n",
       " \"'chandi\",\n",
       " \"'chandler\",\n",
       " \"'change\",\n",
       " \"'changed\",\n",
       " \"'character\",\n",
       " \"'charge\",\n",
       " \"'charges\",\n",
       " \"'chasing\",\n",
       " \"'chattagram\",\n",
       " \"'chatur\",\n",
       " \"'chavs\",\n",
       " \"'cheap\",\n",
       " \"'cheating\",\n",
       " \"'check\",\n",
       " \"'checked\",\n",
       " \"'checkmate\",\n",
       " \"'cheddar\",\n",
       " \"'cheers\",\n",
       " \"'cheese\",\n",
       " \"'chemical\",\n",
       " \"'chemistry\",\n",
       " \"'chest\",\n",
       " \"'chhurpi\",\n",
       " \"'chichora\",\n",
       " \"'chichorapan\",\n",
       " \"'chicken\",\n",
       " \"'chidanand\",\n",
       " \"'chiggy\",\n",
       " \"'child\",\n",
       " \"'childish\",\n",
       " \"'childless\",\n",
       " \"'chin\",\n",
       " \"'china\",\n",
       " \"'chinese\",\n",
       " \"'ching\",\n",
       " \"'chittagong\",\n",
       " \"'chiwetel\",\n",
       " \"'choose\",\n",
       " \"'choosing\",\n",
       " \"'choot\",\n",
       " \"'chopper\",\n",
       " \"'chor\",\n",
       " \"'chosen\",\n",
       " \"'christ\",\n",
       " \"'christian\",\n",
       " \"'christians\",\n",
       " \"'christmas\",\n",
       " \"'chronic\",\n",
       " \"'chummy\",\n",
       " \"'chur\",\n",
       " \"'church\",\n",
       " \"'chyna\",\n",
       " \"'ci\",\n",
       " \"'cina\",\n",
       " \"'circulating\",\n",
       " \"'cisgender\",\n",
       " \"'cisphobic\",\n",
       " \"'cities\",\n",
       " \"'citizen\",\n",
       " \"'citizens\",\n",
       " \"'citrosum\",\n",
       " \"'city\",\n",
       " \"'civil\",\n",
       " \"'civilise\",\n",
       " \"'cl\",\n",
       " \"'claims\",\n",
       " \"'clair\",\n",
       " \"'clark\",\n",
       " \"'claroscuros\",\n",
       " \"'class\",\n",
       " \"'classic\",\n",
       " \"'classical\",\n",
       " \"'classification\",\n",
       " \"'classroom\",\n",
       " \"'classy\",\n",
       " \"'clean\",\n",
       " \"'cleanse\",\n",
       " \"'clear\",\n",
       " \"'clickbait\",\n",
       " \"'client\",\n",
       " \"'climate\",\n",
       " \"'climb\",\n",
       " \"'clinks\",\n",
       " \"'clockwise\",\n",
       " \"'close\",\n",
       " \"'closed\",\n",
       " \"'closeted\",\n",
       " \"'closure\",\n",
       " \"'cloudflare\",\n",
       " \"'clouds\",\n",
       " \"'club\",\n",
       " \"'clueless\",\n",
       " \"'cm\",\n",
       " \"'cng\",\n",
       " \"'co\",\n",
       " \"'coax\",\n",
       " \"'cockroaches\",\n",
       " \"'code\",\n",
       " \"'coded\",\n",
       " \"'codeless\",\n",
       " \"'coder\",\n",
       " \"'coding\",\n",
       " \"'coffee\",\n",
       " \"'coffy\",\n",
       " \"'cogito\",\n",
       " \"'cognitive\",\n",
       " \"'coining\",\n",
       " \"'cold\",\n",
       " \"'coldplay\",\n",
       " \"'collapse\",\n",
       " \"'collective\",\n",
       " \"'college\",\n",
       " \"'colleges'not\",\n",
       " \"'collusion\",\n",
       " \"'colonel\",\n",
       " \"'colonisers\",\n",
       " \"'colony\",\n",
       " \"'colored\",\n",
       " \"'colors\",\n",
       " \"'colourful\",\n",
       " \"'colours\",\n",
       " \"'com\",\n",
       " \"'combine\",\n",
       " \"'come\",\n",
       " \"'comeback\",\n",
       " \"'comedo\",\n",
       " \"'comedone\",\n",
       " \"'comedy\",\n",
       " \"'comets\",\n",
       " \"'comfort\",\n",
       " \"'coming\",\n",
       " \"'commanders\",\n",
       " \"'comment\",\n",
       " \"'commentary\",\n",
       " \"'comments\",\n",
       " \"'commerce\",\n",
       " \"'common\",\n",
       " \"'commonwealth\",\n",
       " \"'communication\",\n",
       " \"'community\",\n",
       " \"'como\",\n",
       " \"'compatibilities\",\n",
       " \"'competitive\",\n",
       " \"'complaint\",\n",
       " \"'complete\",\n",
       " \"'complex\",\n",
       " \"'composite\",\n",
       " \"'composition\",\n",
       " \"'compound\",\n",
       " \"'computer\",\n",
       " \"'computers\",\n",
       " \"'con\",\n",
       " \"'concept\",\n",
       " \"'concert\",\n",
       " \"'concours\",\n",
       " \"'condemn\",\n",
       " \"'confidential\",\n",
       " \"'confirmed\",\n",
       " \"'conflict\",\n",
       " \"'connect\",\n",
       " \"'connected\",\n",
       " \"'connection\",\n",
       " \"'cons\",\n",
       " \"'consent\",\n",
       " \"'consequence\",\n",
       " \"'conservative\",\n",
       " \"'conservatives\",\n",
       " \"'consolidated\",\n",
       " \"'conspiracy\",\n",
       " \"'constant\",\n",
       " \"'constructive\",\n",
       " \"'constructor\",\n",
       " \"'consume\",\n",
       " \"'consumed\",\n",
       " \"'consumer\",\n",
       " \"'consuming\",\n",
       " \"'consumption\",\n",
       " \"'contact\",\n",
       " \"'content\",\n",
       " \"'continue\",\n",
       " \"'continuous\",\n",
       " \"'contrarianism\",\n",
       " \"'contributing\",\n",
       " \"'control\",\n",
       " \"'controversial\",\n",
       " \"'convenient\",\n",
       " \"'convert\",\n",
       " \"'converting\",\n",
       " \"'convince\",\n",
       " \"'cool\",\n",
       " \"'cooler\",\n",
       " \"'coolies\",\n",
       " \"'copper\",\n",
       " \"'copy\",\n",
       " \"'copyright\",\n",
       " \"'copywriter\",\n",
       " \"'coral\",\n",
       " \"'core\",\n",
       " \"'cornerstone\",\n",
       " \"'corporate\",\n",
       " \"'corpse\",\n",
       " \"'correct\",\n",
       " \"'correction\",\n",
       " \"'corrupt\",\n",
       " \"'corrupted\",\n",
       " \"'cortex\",\n",
       " \"'cos\",\n",
       " \"'cosmopolitan\",\n",
       " \"'could\",\n",
       " \"'counselors\",\n",
       " \"'count\",\n",
       " \"'county\",\n",
       " \"'course\",\n",
       " \"'courser\",\n",
       " \"'court\",\n",
       " \"'courting\",\n",
       " \"'cousins\",\n",
       " \"'cout\",\n",
       " \"'covenant\",\n",
       " \"'covered\",\n",
       " \"'covfefe\",\n",
       " \"'cow\",\n",
       " \"'coworking\",\n",
       " \"'coz\",\n",
       " \"'cpec\",\n",
       " \"'crash\",\n",
       " \"'craywings\",\n",
       " \"'crazy\",\n",
       " \"'create\",\n",
       " \"'created\",\n",
       " \"'creating\",\n",
       " \"'creative\",\n",
       " \"'credible\",\n",
       " \"'cricket\",\n",
       " \"'crime\",\n",
       " \"'crimes\",\n",
       " \"'criminal\",\n",
       " \"'cringe\",\n",
       " \"'crisis\",\n",
       " \"'critic\",\n",
       " \"'critical\",\n",
       " \"'critique\",\n",
       " \"'crizal\",\n",
       " \"'croissants\",\n",
       " \"'crook\",\n",
       " \"'crossroads\",\n",
       " \"'crowd\",\n",
       " \"'crown\",\n",
       " \"'crude\",\n",
       " \"'cruelty\",\n",
       " \"'crumbs\",\n",
       " \"'cryptojacking\",\n",
       " \"'cube\",\n",
       " \"'cucciolo\",\n",
       " \"'culling\",\n",
       " \"'cult\",\n",
       " \"'cultural\",\n",
       " \"'culture\",\n",
       " \"'cultured\",\n",
       " \"'cultures\",\n",
       " \"'cum\",\n",
       " \"'curd\",\n",
       " \"'cure\",\n",
       " \"'curiosity\",\n",
       " \"'curiouser\",\n",
       " \"'currencies\",\n",
       " \"'current\",\n",
       " \"'currently\",\n",
       " \"'curse\",\n",
       " \"'cursed\",\n",
       " \"'curvature\",\n",
       " \"'curve\",\n",
       " \"'curvy\",\n",
       " \"'customer\",\n",
       " \"'customized\",\n",
       " \"'cut\",\n",
       " \"'cute\",\n",
       " \"'cuteness\",\n",
       " \"'cuz\",\n",
       " \"'da\",\n",
       " \"'da'\",\n",
       " \"'daane\",\n",
       " \"'dab\",\n",
       " \"'dabeli\",\n",
       " \"'dabiq\",\n",
       " \"'dacca\",\n",
       " \"'dad\",\n",
       " \"'daddy\",\n",
       " \"'daenerys\",\n",
       " \"'dakota\",\n",
       " \"'dal\",\n",
       " \"'dalit\",\n",
       " \"'damaged\",\n",
       " \"'damn\",\n",
       " \"'dance\",\n",
       " \"'dangal\",\n",
       " \"'dangers\",\n",
       " \"'dapper\",\n",
       " \"'darbian\",\n",
       " \"'daredevil\",\n",
       " \"'dark\",\n",
       " \"'darn'on\",\n",
       " \"'darwaaza\",\n",
       " \"'das\",\n",
       " \"'dashboard\",\n",
       " \"'data\",\n",
       " \"'datacenter\",\n",
       " \"'date\",\n",
       " \"'dating\",\n",
       " \"'daughters\",\n",
       " \"'david\",\n",
       " \"'dawn\",\n",
       " \"'day\",\n",
       " \"'dbname\",\n",
       " \"'de\",\n",
       " \"'dead\",\n",
       " \"'deal\",\n",
       " \"'dear\",\n",
       " \"'dearness\",\n",
       " \"'death\",\n",
       " \"'debate\",\n",
       " \"'deceive\",\n",
       " \"'decimate\",\n",
       " \"'decision\",\n",
       " \"'decisive\",\n",
       " \"'dedicated\",\n",
       " \"'deed\",\n",
       " \"'deep\",\n",
       " \"'deeply\",\n",
       " \"'default\",\n",
       " \"'defence\",\n",
       " \"'deference\",\n",
       " \"'definition\",\n",
       " \"'deja\",\n",
       " \"'del\",\n",
       " \"'delegates\",\n",
       " \"'delete\",\n",
       " \"'delhi\",\n",
       " \"'deliberate\",\n",
       " \"'delighting\",\n",
       " \"'delinquency\",\n",
       " \"'delivery\",\n",
       " \"'democracy\",\n",
       " \"'demonisation\",\n",
       " \"'deniers\",\n",
       " \"'denso\",\n",
       " \"'deny\",\n",
       " \"'deplatforming\",\n",
       " \"'deport\",\n",
       " \"'deposits\",\n",
       " \"'depression\",\n",
       " \"'depressive\",\n",
       " \"'derivative\",\n",
       " \"'describe\",\n",
       " \"'deserts\",\n",
       " \"'deserve\",\n",
       " \"'deserved\",\n",
       " \"'deshdrohi\",\n",
       " \"'despacito\",\n",
       " \"'desperate\",\n",
       " \"'destabilizing\",\n",
       " \"'destiny\",\n",
       " \"'destring\",\n",
       " \"'destroy\",\n",
       " \"'determinant\",\n",
       " \"'detroit\",\n",
       " \"'deus\",\n",
       " \"'devaluation\",\n",
       " \"'developed\",\n",
       " \"'developing\",\n",
       " \"'development\",\n",
       " \"'device\",\n",
       " \"'devil\",\n",
       " \"'devotee\",\n",
       " \"'devout\",\n",
       " \"'dhaba\",\n",
       " \"'dhaka\",\n",
       " \"'dharians\",\n",
       " \"'dharna\",\n",
       " \"'dhokha\",\n",
       " \"'dhoti\",\n",
       " \"'di\",\n",
       " \"'diagnosis\",\n",
       " \"'dialectic\",\n",
       " \"'dialects\",\n",
       " \"'dick\",\n",
       " \"'did\",\n",
       " \"'die\",\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"''how\",\n",
       " \"''kate\",\n",
       " \"''national\",\n",
       " \"''religion\",\n",
       " \"''that\",\n",
       " \"''why\",\n",
       " \"'0\",\n",
       " \"'00000000000000000021e800\",\n",
       " \"'00s\",\n",
       " \"'1\",\n",
       " \"'1'54'am\",\n",
       " \"'100\",\n",
       " \"'102\",\n",
       " \"'10x\",\n",
       " \"'110\",\n",
       " \"'1967\",\n",
       " \"'200\",\n",
       " \"'2009\",\n",
       " \"'2099\",\n",
       " \"'2nd\",\n",
       " \"'2r\",\n",
       " \"'3\",\n",
       " \"'301\",\n",
       " \"'4\",\n",
       " \"'4'\",\n",
       " \"'4'it\",\n",
       " \"'403\",\n",
       " \"'4k\",\n",
       " \"'5\",\n",
       " \"'500\",\n",
       " \"'539\",\n",
       " \"'6\",\n",
       " \"'666\",\n",
       " \"'7\",\n",
       " \"'777888999\",\n",
       " \"'8\",\n",
       " \"'a\",\n",
       " \"'a'units\",\n",
       " \"'a2a\",\n",
       " \"'aa\",\n",
       " \"'aaji\",\n",
       " \"'aajkal\",\n",
       " \"'aap\",\n",
       " \"'aazadi\",\n",
       " \"'ab\",\n",
       " \"'abdullah\",\n",
       " \"'ability\",\n",
       " \"'abode\",\n",
       " \"'abortion\",\n",
       " \"'about\",\n",
       " \"'above\",\n",
       " \"'abracadabra\",\n",
       " \"'abuse\",\n",
       " \"'acceleration\",\n",
       " \"'accept\",\n",
       " \"'acceptable\",\n",
       " \"'access\",\n",
       " \"'accha\",\n",
       " \"'accident\",\n",
       " \"'accidental\",\n",
       " \"'accidentally\",\n",
       " \"'acclaimed\",\n",
       " \"'accomplishments\",\n",
       " \"'accurate\",\n",
       " \"'accuser\",\n",
       " \"'achievement\",\n",
       " \"'act\",\n",
       " \"'acting\",\n",
       " \"'actioning\",\n",
       " \"'active\",\n",
       " \"'actively\",\n",
       " \"'actor\",\n",
       " \"'actors\",\n",
       " \"'actually\",\n",
       " \"'adam\",\n",
       " \"'adapted\",\n",
       " \"'adaption\",\n",
       " \"'adat\",\n",
       " \"'add\",\n",
       " \"'addams\",\n",
       " \"'addicting\",\n",
       " \"'addictive\",\n",
       " \"'additional\",\n",
       " \"'adds\",\n",
       " \"'adiye\",\n",
       " \"'adjust\",\n",
       " \"'administrators\",\n",
       " \"'adobe\",\n",
       " \"'adoctrinamiento\",\n",
       " \"'adolf\",\n",
       " \"'adolph\",\n",
       " \"'adoptive\",\n",
       " \"'adult\",\n",
       " \"'advanced\",\n",
       " \"'advisor\",\n",
       " \"'advocacy\",\n",
       " \"'afflict\",\n",
       " \"'affray\",\n",
       " \"'afra\",\n",
       " \"'afreen\",\n",
       " \"'after\",\n",
       " \"'agar\",\n",
       " \"'age\",\n",
       " \"'aged\",\n",
       " \"'ageing\",\n",
       " \"'agender\",\n",
       " \"'ago\",\n",
       " \"'agree\",\n",
       " \"'ah\",\n",
       " \"'aha\",\n",
       " \"'aham\",\n",
       " \"'ahmadis\",\n",
       " \"'aib\",\n",
       " \"'air\",\n",
       " \"'airline\",\n",
       " \"'airplane\",\n",
       " \"'airtel\",\n",
       " \"'aisha\",\n",
       " \"'aishwarya\",\n",
       " \"'akale\",\n",
       " \"'akhanda\",\n",
       " \"'akinator\",\n",
       " \"'aksar\",\n",
       " \"'al\",\n",
       " \"'alastor\",\n",
       " \"'albino\",\n",
       " \"'alex\",\n",
       " \"'algorithm\",\n",
       " \"'alhamdulillah\",\n",
       " \"'ali\",\n",
       " \"'alias\",\n",
       " \"'alice\",\n",
       " \"'alien\",\n",
       " \"'aliens\",\n",
       " \"'alive\",\n",
       " \"'all\",\n",
       " \"'allahu\",\n",
       " \"'alleged\",\n",
       " \"'allegedly\",\n",
       " \"'allegretto\",\n",
       " \"'allison\",\n",
       " \"'aloko\",\n",
       " \"'alpaca\",\n",
       " \"'alplexle\",\n",
       " \"'also\",\n",
       " \"'alt\",\n",
       " \"'altaba\",\n",
       " \"'alternative\",\n",
       " \"'alternote\",\n",
       " \"'always\",\n",
       " \"'am\",\n",
       " \"'amar\",\n",
       " \"'amateur\",\n",
       " \"'amazigh\",\n",
       " \"'amazon\",\n",
       " \"'ambani\",\n",
       " \"'ambulance\",\n",
       " \"'america\",\n",
       " \"'american\",\n",
       " \"'americans\",\n",
       " \"'americasians\",\n",
       " \"'amnesty\",\n",
       " \"'among\",\n",
       " \"'amy\",\n",
       " \"'an\",\n",
       " \"'analog\",\n",
       " \"'ananupurvi\",\n",
       " \"'anarchist\",\n",
       " \"'anarchy\",\n",
       " \"'ancient\",\n",
       " \"'and\",\n",
       " \"'andromaque\",\n",
       " \"'anecdotal\",\n",
       " \"'anekantwad\",\n",
       " \"'angel\",\n",
       " \"'angelic\",\n",
       " \"'anger\",\n",
       " \"'angry\",\n",
       " \"'animal\",\n",
       " \"'animalistic\",\n",
       " \"'animals\",\n",
       " \"'ankeeta\",\n",
       " \"'annapai\",\n",
       " \"'annoyed\",\n",
       " \"'annoying\",\n",
       " \"'annual\",\n",
       " \"'annuity\",\n",
       " \"'annum\",\n",
       " \"'anonymous\",\n",
       " \"'anonymously\",\n",
       " \"'anoop\",\n",
       " \"'ans\",\n",
       " \"'answer\",\n",
       " \"'ant\",\n",
       " \"'antaryami\",\n",
       " \"'anthropophobia\",\n",
       " \"'anti\",\n",
       " \"'anticipation\",\n",
       " \"'antifa\",\n",
       " \"'antigens\",\n",
       " \"'antiquities\",\n",
       " \"'antisemitic\",\n",
       " \"'anxiety\",\n",
       " \"'any\",\n",
       " \"'anything\",\n",
       " \"'anyway\",\n",
       " \"'anyways\",\n",
       " \"'apartheid\",\n",
       " \"'apoapsis\",\n",
       " \"'apologized\",\n",
       " \"'apology\",\n",
       " \"'app\",\n",
       " \"'apparatus\",\n",
       " \"'apparent\",\n",
       " \"'apparently\",\n",
       " \"'appearing\",\n",
       " \"'appeasement\",\n",
       " \"'apple\",\n",
       " \"'appreciation\",\n",
       " \"'approach\",\n",
       " \"'apyayatha\",\n",
       " \"'arab\",\n",
       " \"'arabian\",\n",
       " \"'arbitrary\",\n",
       " \"'archer\",\n",
       " \"'architecture\",\n",
       " \"'are\",\n",
       " \"'arifi\",\n",
       " \"'arijit\",\n",
       " \"'arjuna\",\n",
       " \"'arm\",\n",
       " \"'armed\",\n",
       " \"'armour\",\n",
       " \"'arpita\",\n",
       " \"'arrests\",\n",
       " \"'arrival\",\n",
       " \"'arrow\",\n",
       " \"'art\",\n",
       " \"'article\",\n",
       " \"'artificial\",\n",
       " \"'aruvi\",\n",
       " \"'as\",\n",
       " \"'ashkenazi\",\n",
       " \"'asians\",\n",
       " \"'ask\",\n",
       " \"'askreddit\",\n",
       " \"'asleeping\",\n",
       " \"'ass\",\n",
       " \"'assault\",\n",
       " \"'assigned\",\n",
       " \"'association\",\n",
       " \"'asuras\",\n",
       " \"'at\",\n",
       " \"'ataturk\",\n",
       " \"'ate\",\n",
       " \"'atheism\",\n",
       " \"'atheist\",\n",
       " \"'ati\",\n",
       " \"'atom\",\n",
       " \"'atomic\",\n",
       " \"'atrocity\",\n",
       " \"'attack\",\n",
       " \"'attacks\",\n",
       " \"'attractive\",\n",
       " \"'audacious\",\n",
       " \"'audacity\",\n",
       " \"'aukad\",\n",
       " \"'aunty\",\n",
       " \"'aurangzeb\",\n",
       " \"'authentic'\",\n",
       " \"'author'\",\n",
       " \"'authored\",\n",
       " \"'authorities\",\n",
       " \"'authority\",\n",
       " \"'avada\",\n",
       " \"'avengers\",\n",
       " \"'average\",\n",
       " \"'avoid\",\n",
       " \"'award\",\n",
       " \"'awkward\",\n",
       " \"'awrt\",\n",
       " \"'axiom\",\n",
       " \"'axon\",\n",
       " \"'ayesha\",\n",
       " \"'azerbaijani\",\n",
       " \"'b\",\n",
       " \"'b2\",\n",
       " \"'b3\",\n",
       " \"'baadshaho\",\n",
       " \"'baahubali\",\n",
       " \"'baalig\",\n",
       " \"'baba\",\n",
       " \"'babe\",\n",
       " \"'babies\",\n",
       " \"'babu\",\n",
       " \"'baby\",\n",
       " \"'baccha\",\n",
       " \"'bacha\",\n",
       " \"'bachche\",\n",
       " \"'bachelor\",\n",
       " \"'bachelors\",\n",
       " \"'back\",\n",
       " \"'background\",\n",
       " \"'backlog\",\n",
       " \"'bacon\",\n",
       " \"'bad\",\n",
       " \"'badly\",\n",
       " \"'bae\",\n",
       " \"'bagvadgita\",\n",
       " \"'baidu\",\n",
       " \"'bakkushan\",\n",
       " \"'baklava\",\n",
       " \"'bal\",\n",
       " \"'balaclava\",\n",
       " \"'balances\",\n",
       " \"'ballad\",\n",
       " \"'bama\",\n",
       " \"'band\",\n",
       " \"'bandhan\",\n",
       " \"'bang\",\n",
       " \"'bangladesh\",\n",
       " \"'bangladeshis\",\n",
       " \"'banglore\",\n",
       " \"'baniya\",\n",
       " \"'baniyas\",\n",
       " \"'bank\",\n",
       " \"'bankable\",\n",
       " \"'banking\",\n",
       " \"'bankroll\",\n",
       " \"'bar\",\n",
       " \"'bare\",\n",
       " \"'barka\",\n",
       " \"'bart\",\n",
       " \"'barter\",\n",
       " \"'basal\",\n",
       " \"'base\",\n",
       " \"'based\",\n",
       " \"'baselining\",\n",
       " \"'basic\",\n",
       " \"'basics\",\n",
       " \"'basing\",\n",
       " \"'basket\",\n",
       " \"'batman\",\n",
       " \"'battle\",\n",
       " \"'bbc\",\n",
       " \"'be\",\n",
       " \"'beautiful\",\n",
       " \"'became\",\n",
       " \"'because\",\n",
       " \"'becky\",\n",
       " \"'become\",\n",
       " \"'becoming\",\n",
       " \"'before\",\n",
       " \"'behavioral\",\n",
       " \"'behavioural\",\n",
       " \"'behind\",\n",
       " \"'being\",\n",
       " \"'belief\",\n",
       " \"'believe\",\n",
       " \"'believers\",\n",
       " \"'believing\",\n",
       " \"'belle\",\n",
       " \"'belly\",\n",
       " \"'ben\",\n",
       " \"'bender\",\n",
       " \"'bending\",\n",
       " \"'benefit\",\n",
       " \"'bengaluru\",\n",
       " \"'berkeley\",\n",
       " \"'berserk\",\n",
       " \"'best\",\n",
       " \"'bestfriends\",\n",
       " \"'bet\",\n",
       " \"'beta\",\n",
       " \"'beti\",\n",
       " \"'better\",\n",
       " \"'between\",\n",
       " \"'beurette\",\n",
       " \"'bey\",\n",
       " \"'beyhadh\",\n",
       " \"'beyond\",\n",
       " \"'bhagwan\",\n",
       " \"'bhaisaheb\",\n",
       " \"'bhakt\",\n",
       " \"'bhakts\",\n",
       " \"'bhandary\",\n",
       " \"'bhangi\",\n",
       " \"'bharat\",\n",
       " \"'bhavesh\",\n",
       " \"'bheege\",\n",
       " \"'bhim\",\n",
       " \"'bhutta\",\n",
       " \"'bic\",\n",
       " \"'bien\",\n",
       " \"'big\",\n",
       " \"'bigger\",\n",
       " \"'biggest\",\n",
       " \"'bigly\",\n",
       " \"'bill\",\n",
       " \"'billionaire\",\n",
       " \"'billy\",\n",
       " \"'bimbo\",\n",
       " \"'bind\",\n",
       " \"'biogical\",\n",
       " \"'bioinformatics\",\n",
       " \"'birds\",\n",
       " \"'birth\",\n",
       " \"'bit\",\n",
       " \"'bitch\",\n",
       " \"'bitcheese\",\n",
       " \"'bitches\",\n",
       " \"'bitcoin\",\n",
       " \"'biting\",\n",
       " \"'bjp\",\n",
       " \"'black\",\n",
       " \"'blacker\",\n",
       " \"'blacking\",\n",
       " \"'blacklist\",\n",
       " \"'blacklisted\",\n",
       " \"'blackmail\",\n",
       " \"'blacks\",\n",
       " \"'blah\",\n",
       " \"'blaming\",\n",
       " \"'blanket\",\n",
       " \"'blasphemers\",\n",
       " \"'bleach\",\n",
       " \"'bless\",\n",
       " \"'blessed\",\n",
       " \"'blinded\",\n",
       " \"'blindspot\",\n",
       " \"'blockchain\",\n",
       " \"'blogger\",\n",
       " \"'blood\",\n",
       " \"'blown\",\n",
       " \"'blue\",\n",
       " \"'blueprints\",\n",
       " \"'blues\",\n",
       " \"'bluetooth\",\n",
       " \"'blunder\",\n",
       " \"'blur\",\n",
       " \"'bob\",\n",
       " \"'bodhgaya\",\n",
       " \"'body\",\n",
       " \"'bohemian\",\n",
       " \"'boli\",\n",
       " \"'bolsomito\",\n",
       " \"'bomb\",\n",
       " \"'bonanza\",\n",
       " \"'bond\",\n",
       " \"'bone\",\n",
       " \"'bonespur\",\n",
       " \"'boneyard\",\n",
       " \"'boo\",\n",
       " \"'boobs\",\n",
       " \"'book\",\n",
       " \"'boom\",\n",
       " \"'boondocks\",\n",
       " \"'boot\",\n",
       " \"'bootstrap\",\n",
       " \"'booty\",\n",
       " \"'boring\",\n",
       " \"'born\",\n",
       " \"'borrow\",\n",
       " \"'bossy\",\n",
       " \"'bot\",\n",
       " \"'both\",\n",
       " \"'bots\",\n",
       " \"'bottle\",\n",
       " \"'bottom\",\n",
       " \"'bought\",\n",
       " \"'bounce\",\n",
       " \"'bovanoskification\",\n",
       " \"'box\",\n",
       " \"'boxes\",\n",
       " \"'boys\",\n",
       " \"'brahmin\",\n",
       " \"'brain\",\n",
       " \"'brainstorm\",\n",
       " \"'brainwash\",\n",
       " \"'branching\",\n",
       " \"'brand\",\n",
       " \"'brandless\",\n",
       " \"'brasil\",\n",
       " \"'brass\",\n",
       " \"'brave\",\n",
       " \"'bravo\",\n",
       " \"'brazil\",\n",
       " \"'breach\",\n",
       " \"'bread\",\n",
       " \"'break\",\n",
       " \"'breakeven\",\n",
       " \"'breaks\",\n",
       " \"'breathe\",\n",
       " \"'breed\",\n",
       " \"'brexit\",\n",
       " \"'bridge\",\n",
       " \"'bridges\",\n",
       " \"'bright\",\n",
       " \"'brightest\",\n",
       " \"'bring\",\n",
       " \"'briony\",\n",
       " \"'brit\",\n",
       " \"'britain\",\n",
       " \"'british\",\n",
       " \"'britons\",\n",
       " \"'bro\",\n",
       " \"'broadway\",\n",
       " \"'broken\",\n",
       " \"'bronzemann\",\n",
       " \"'brother\",\n",
       " \"'brown\",\n",
       " \"'brownie\",\n",
       " \"'browse\",\n",
       " \"'bruce\",\n",
       " \"'bruh\",\n",
       " \"'bts\",\n",
       " \"'buggy\",\n",
       " \"'bullet\",\n",
       " \"'bullied\",\n",
       " \"'bullies\",\n",
       " \"'bullseye\",\n",
       " \"'bungalow\",\n",
       " \"'burden\",\n",
       " \"'bureaucracy\",\n",
       " \"'burn\",\n",
       " \"'burning\",\n",
       " \"'burnt\",\n",
       " \"'burp\",\n",
       " \"'burq\",\n",
       " \"'bushism\",\n",
       " \"'business\",\n",
       " \"'bust\",\n",
       " \"'busy\",\n",
       " \"'but\",\n",
       " \"'butt\",\n",
       " \"'butterface\",\n",
       " \"'butterfly\",\n",
       " \"'button\",\n",
       " \"'buy\",\n",
       " \"'buying\",\n",
       " \"'by\",\n",
       " \"'bystander\",\n",
       " \"'byte\",\n",
       " \"'c\",\n",
       " \"'ca\",\n",
       " \"'cable\",\n",
       " \"'cabover\",\n",
       " \"'cagnolino\",\n",
       " \"'calculate\",\n",
       " \"'calendar\",\n",
       " \"'calf\",\n",
       " \"'calibrated\",\n",
       " \"'california\",\n",
       " \"'call\",\n",
       " \"'called\",\n",
       " \"'calling\",\n",
       " \"'calls\",\n",
       " \"'cally\",\n",
       " \"'camila\",\n",
       " \"'camp\",\n",
       " \"'campaign\",\n",
       " \"'can\",\n",
       " \"'canada\",\n",
       " \"'canadian\",\n",
       " \"'candidate\",\n",
       " \"'capacitance\",\n",
       " \"'capitalism\",\n",
       " \"'capitalist\",\n",
       " \"'carbon\",\n",
       " \"'care\",\n",
       " \"'careless\",\n",
       " \"'carly\",\n",
       " \"'carried\",\n",
       " \"'carrier\",\n",
       " \"'cart\",\n",
       " \"'cases\",\n",
       " \"'cash\",\n",
       " \"'cashed\",\n",
       " \"'cashless\",\n",
       " \"'cast\",\n",
       " \"'caste\",\n",
       " \"'casting\",\n",
       " \"'castle\",\n",
       " \"'casual\",\n",
       " \"'catching\",\n",
       " \"'category\",\n",
       " \"'catfishing\",\n",
       " \"'cathedral\",\n",
       " \"'catherine\",\n",
       " \"'cats\",\n",
       " \"'cattle\",\n",
       " \"'catwalking\",\n",
       " \"'causal\",\n",
       " \"'causative\",\n",
       " \"'ce\",\n",
       " \"'cecilia\",\n",
       " \"'celebrity\",\n",
       " \"'celestial\",\n",
       " \"'cell\",\n",
       " \"'center\",\n",
       " \"'central\",\n",
       " \"'centrists\",\n",
       " \"'certainty\",\n",
       " \"'certified\",\n",
       " \"'chah\",\n",
       " \"'chai\",\n",
       " \"'chain\",\n",
       " \"'chaiwala\",\n",
       " \"'chalta\",\n",
       " \"'chamcha\",\n",
       " \"'chamchagiri\",\n",
       " \"'chamchas\",\n",
       " \"'chandi\",\n",
       " \"'chandler\",\n",
       " \"'change\",\n",
       " \"'changed\",\n",
       " \"'character\",\n",
       " \"'charge\",\n",
       " \"'charges\",\n",
       " \"'chasing\",\n",
       " \"'chattagram\",\n",
       " \"'chatur\",\n",
       " \"'chavs\",\n",
       " \"'cheap\",\n",
       " \"'cheating\",\n",
       " \"'check\",\n",
       " \"'checked\",\n",
       " \"'checkmate\",\n",
       " \"'cheddar\",\n",
       " \"'cheers\",\n",
       " \"'cheese\",\n",
       " \"'chemical\",\n",
       " \"'chemistry\",\n",
       " \"'chest\",\n",
       " \"'chhurpi\",\n",
       " \"'chichora\",\n",
       " \"'chichorapan\",\n",
       " \"'chicken\",\n",
       " \"'chidanand\",\n",
       " \"'chiggy\",\n",
       " \"'child\",\n",
       " \"'childish\",\n",
       " \"'childless\",\n",
       " \"'chin\",\n",
       " \"'china\",\n",
       " \"'chinese\",\n",
       " \"'ching\",\n",
       " \"'chittagong\",\n",
       " \"'chiwetel\",\n",
       " \"'choose\",\n",
       " \"'choosing\",\n",
       " \"'choot\",\n",
       " \"'chopper\",\n",
       " \"'chor\",\n",
       " \"'chosen\",\n",
       " \"'christ\",\n",
       " \"'christian\",\n",
       " \"'christians\",\n",
       " \"'christmas\",\n",
       " \"'chronic\",\n",
       " \"'chummy\",\n",
       " \"'chur\",\n",
       " \"'church\",\n",
       " \"'chyna\",\n",
       " \"'ci\",\n",
       " \"'cina\",\n",
       " \"'circulating\",\n",
       " \"'cisgender\",\n",
       " \"'cisphobic\",\n",
       " \"'cities\",\n",
       " \"'citizen\",\n",
       " \"'citizens\",\n",
       " \"'citrosum\",\n",
       " \"'city\",\n",
       " \"'civil\",\n",
       " \"'civilise\",\n",
       " \"'cl\",\n",
       " \"'claims\",\n",
       " \"'clair\",\n",
       " \"'clark\",\n",
       " \"'claroscuros\",\n",
       " \"'class\",\n",
       " \"'classic\",\n",
       " \"'classical\",\n",
       " \"'classification\",\n",
       " \"'classroom\",\n",
       " \"'classy\",\n",
       " \"'clean\",\n",
       " \"'cleanse\",\n",
       " \"'clear\",\n",
       " \"'clickbait\",\n",
       " \"'client\",\n",
       " \"'climate\",\n",
       " \"'climb\",\n",
       " \"'clinks\",\n",
       " \"'clockwise\",\n",
       " \"'close\",\n",
       " \"'closed\",\n",
       " \"'closeted\",\n",
       " \"'closure\",\n",
       " \"'cloudflare\",\n",
       " \"'clouds\",\n",
       " \"'club\",\n",
       " \"'clueless\",\n",
       " \"'cm\",\n",
       " \"'cng\",\n",
       " \"'co\",\n",
       " \"'coax\",\n",
       " \"'cockroaches\",\n",
       " \"'code\",\n",
       " \"'coded\",\n",
       " \"'codeless\",\n",
       " \"'coder\",\n",
       " \"'coding\",\n",
       " \"'coffee\",\n",
       " \"'coffy\",\n",
       " \"'cogito\",\n",
       " \"'cognitive\",\n",
       " \"'coining\",\n",
       " \"'cold\",\n",
       " \"'coldplay\",\n",
       " \"'collapse\",\n",
       " \"'collective\",\n",
       " \"'college\",\n",
       " \"'colleges'not\",\n",
       " \"'collusion\",\n",
       " \"'colonel\",\n",
       " \"'colonisers\",\n",
       " \"'colony\",\n",
       " \"'colored\",\n",
       " \"'colors\",\n",
       " \"'colourful\",\n",
       " \"'colours\",\n",
       " \"'com\",\n",
       " \"'combine\",\n",
       " \"'come\",\n",
       " \"'comeback\",\n",
       " \"'comedo\",\n",
       " \"'comedone\",\n",
       " \"'comedy\",\n",
       " \"'comets\",\n",
       " \"'comfort\",\n",
       " \"'coming\",\n",
       " \"'commanders\",\n",
       " \"'comment\",\n",
       " \"'commentary\",\n",
       " \"'comments\",\n",
       " \"'commerce\",\n",
       " \"'common\",\n",
       " \"'commonwealth\",\n",
       " \"'communication\",\n",
       " \"'community\",\n",
       " \"'como\",\n",
       " \"'compatibilities\",\n",
       " \"'competitive\",\n",
       " \"'complaint\",\n",
       " \"'complete\",\n",
       " \"'complex\",\n",
       " \"'composite\",\n",
       " \"'composition\",\n",
       " \"'compound\",\n",
       " \"'computer\",\n",
       " \"'computers\",\n",
       " \"'con\",\n",
       " \"'concept\",\n",
       " \"'concert\",\n",
       " \"'concours\",\n",
       " \"'condemn\",\n",
       " \"'confidential\",\n",
       " \"'confirmed\",\n",
       " \"'conflict\",\n",
       " \"'connect\",\n",
       " \"'connected\",\n",
       " \"'connection\",\n",
       " \"'cons\",\n",
       " \"'consent\",\n",
       " \"'consequence\",\n",
       " \"'conservative\",\n",
       " \"'conservatives\",\n",
       " \"'consolidated\",\n",
       " \"'conspiracy\",\n",
       " \"'constant\",\n",
       " \"'constructive\",\n",
       " \"'constructor\",\n",
       " \"'consume\",\n",
       " \"'consumed\",\n",
       " \"'consumer\",\n",
       " \"'consuming\",\n",
       " \"'consumption\",\n",
       " \"'contact\",\n",
       " \"'content\",\n",
       " \"'continue\",\n",
       " \"'continuous\",\n",
       " \"'contrarianism\",\n",
       " \"'contributing\",\n",
       " \"'control\",\n",
       " \"'controversial\",\n",
       " \"'convenient\",\n",
       " \"'convert\",\n",
       " \"'converting\",\n",
       " \"'convince\",\n",
       " \"'cool\",\n",
       " \"'cooler\",\n",
       " \"'coolies\",\n",
       " \"'copper\",\n",
       " \"'copy\",\n",
       " \"'copyright\",\n",
       " \"'copywriter\",\n",
       " \"'coral\",\n",
       " \"'core\",\n",
       " \"'cornerstone\",\n",
       " \"'corporate\",\n",
       " \"'corpse\",\n",
       " \"'correct\",\n",
       " \"'correction\",\n",
       " \"'corrupt\",\n",
       " \"'corrupted\",\n",
       " \"'cortex\",\n",
       " \"'cos\",\n",
       " \"'cosmopolitan\",\n",
       " \"'could\",\n",
       " \"'counselors\",\n",
       " \"'count\",\n",
       " \"'county\",\n",
       " \"'course\",\n",
       " \"'courser\",\n",
       " \"'court\",\n",
       " \"'courting\",\n",
       " \"'cousins\",\n",
       " \"'cout\",\n",
       " \"'covenant\",\n",
       " \"'covered\",\n",
       " \"'covfefe\",\n",
       " \"'cow\",\n",
       " \"'coworking\",\n",
       " \"'coz\",\n",
       " \"'cpec\",\n",
       " \"'crash\",\n",
       " \"'craywings\",\n",
       " \"'crazy\",\n",
       " \"'create\",\n",
       " \"'created\",\n",
       " \"'creating\",\n",
       " \"'creative\",\n",
       " \"'credible\",\n",
       " \"'cricket\",\n",
       " \"'crime\",\n",
       " \"'crimes\",\n",
       " \"'criminal\",\n",
       " \"'cringe\",\n",
       " \"'crisis\",\n",
       " \"'critic\",\n",
       " \"'critical\",\n",
       " \"'critique\",\n",
       " \"'crizal\",\n",
       " \"'croissants\",\n",
       " \"'crook\",\n",
       " \"'crossroads\",\n",
       " \"'crowd\",\n",
       " \"'crown\",\n",
       " \"'crude\",\n",
       " \"'cruelty\",\n",
       " \"'crumbs\",\n",
       " \"'cryptojacking\",\n",
       " \"'cube\",\n",
       " \"'cucciolo\",\n",
       " \"'culling\",\n",
       " \"'cult\",\n",
       " \"'cultural\",\n",
       " \"'culture\",\n",
       " \"'cultured\",\n",
       " \"'cultures\",\n",
       " \"'cum\",\n",
       " \"'curd\",\n",
       " \"'cure\",\n",
       " \"'curiosity\",\n",
       " \"'curiouser\",\n",
       " \"'currencies\",\n",
       " \"'current\",\n",
       " \"'currently\",\n",
       " \"'curse\",\n",
       " \"'cursed\",\n",
       " \"'curvature\",\n",
       " \"'curve\",\n",
       " \"'curvy\",\n",
       " \"'customer\",\n",
       " \"'customized\",\n",
       " \"'cut\",\n",
       " \"'cute\",\n",
       " \"'cuteness\",\n",
       " \"'cuz\",\n",
       " \"'da\",\n",
       " \"'da'\",\n",
       " \"'daane\",\n",
       " \"'dab\",\n",
       " \"'dabeli\",\n",
       " \"'dabiq\",\n",
       " \"'dacca\",\n",
       " \"'dad\",\n",
       " \"'daddy\",\n",
       " \"'daenerys\",\n",
       " \"'dakota\",\n",
       " \"'dal\",\n",
       " \"'dalit\",\n",
       " \"'damaged\",\n",
       " \"'damn\",\n",
       " \"'dance\",\n",
       " \"'dangal\",\n",
       " \"'dangers\",\n",
       " \"'dapper\",\n",
       " \"'darbian\",\n",
       " \"'daredevil\",\n",
       " \"'dark\",\n",
       " \"'darn'on\",\n",
       " \"'darwaaza\",\n",
       " \"'das\",\n",
       " \"'dashboard\",\n",
       " \"'data\",\n",
       " \"'datacenter\",\n",
       " \"'date\",\n",
       " \"'dating\",\n",
       " \"'daughters\",\n",
       " \"'david\",\n",
       " \"'dawn\",\n",
       " \"'day\",\n",
       " \"'dbname\",\n",
       " \"'de\",\n",
       " \"'dead\",\n",
       " \"'deal\",\n",
       " \"'dear\",\n",
       " \"'dearness\",\n",
       " \"'death\",\n",
       " \"'debate\",\n",
       " \"'deceive\",\n",
       " \"'decimate\",\n",
       " \"'decision\",\n",
       " \"'decisive\",\n",
       " \"'dedicated\",\n",
       " \"'deed\",\n",
       " \"'deep\",\n",
       " \"'deeply\",\n",
       " \"'default\",\n",
       " \"'defence\",\n",
       " \"'deference\",\n",
       " \"'definition\",\n",
       " \"'deja\",\n",
       " \"'del\",\n",
       " \"'delegates\",\n",
       " \"'delete\",\n",
       " \"'delhi\",\n",
       " \"'deliberate\",\n",
       " \"'delighting\",\n",
       " \"'delinquency\",\n",
       " \"'delivery\",\n",
       " \"'democracy\",\n",
       " \"'demonisation\",\n",
       " \"'deniers\",\n",
       " \"'denso\",\n",
       " \"'deny\",\n",
       " \"'deplatforming\",\n",
       " \"'deport\",\n",
       " \"'deposits\",\n",
       " \"'depression\",\n",
       " \"'depressive\",\n",
       " \"'derivative\",\n",
       " \"'describe\",\n",
       " \"'deserts\",\n",
       " \"'deserve\",\n",
       " \"'deserved\",\n",
       " \"'deshdrohi\",\n",
       " \"'despacito\",\n",
       " \"'desperate\",\n",
       " \"'destabilizing\",\n",
       " \"'destiny\",\n",
       " \"'destring\",\n",
       " \"'destroy\",\n",
       " \"'determinant\",\n",
       " \"'detroit\",\n",
       " \"'deus\",\n",
       " \"'devaluation\",\n",
       " \"'developed\",\n",
       " \"'developing\",\n",
       " \"'development\",\n",
       " \"'device\",\n",
       " \"'devil\",\n",
       " \"'devotee\",\n",
       " \"'devout\",\n",
       " \"'dhaba\",\n",
       " \"'dhaka\",\n",
       " \"'dharians\",\n",
       " \"'dharna\",\n",
       " \"'dhokha\",\n",
       " \"'dhoti\",\n",
       " \"'di\",\n",
       " \"'diagnosis\",\n",
       " \"'dialectic\",\n",
       " \"'dialects\",\n",
       " \"'dick\",\n",
       " \"'did\",\n",
       " \"'die\",\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragram_oov"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
